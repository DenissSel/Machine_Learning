{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Алгоритмы интеллектуальной обработки больших объемов данных\n",
    "## Домашнее задание №4 - Градиентный бустинг\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Общая информация**\n",
    "\n",
    "**Срок сдачи:** 13 июня 2022, 08:30   \n",
    "**Штраф за опоздание:** -2 балла после 08:30 13 июня, -4 балла после 08:30 20 июня, -6 баллов после 08:30 24 мая, -8 баллов после 08:30 31 мая.\n",
    "\n",
    "При отправлении ДЗ указывайте фамилию в названии файла Присылать ДЗ необходимо в виде ссылки на свой github репозиторий на почту ml1.sphere@mail.ru с указанием темы в следующем формате:\n",
    "[ML0422, Задание 4] Фамилия Имя. \n",
    "\n",
    "\n",
    "Используйте данный Ipython Notebook при оформлении домашнего задания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Считаем производные для функций потерь (1 балл)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы будем реализовать градиентный бустинг для 3 функций потерь:\n",
    "\n",
    "1) MSE  $L(a(x_i), y_i) = (y_i - a(x_i)) ^ 2$\n",
    "\n",
    "2) Экспоненциальная  $L(a(x_i), y_i) = exp( -a(x_i) y_i), y_i \\in \\{-1, 1\\}$\n",
    "\n",
    "3) Логистическая  $L(a(x_i), y_i) = \\log (1 + exp( -a(x_i) y_i)), y_i \\in \\{-1, 1\\}$\n",
    "\n",
    "где $a(x_i)$ предсказание бустинга на итом объекте. \n",
    "\n",
    "Для каждой функции потерь напишите таргет, на который будет настраиваться каждое дерево в бустинге. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1). k+1-е дерево будет настраиваться на $2(y_i - a_k(x_i)) $, где $a_k$ - это предсказание первых k деревьев\n",
    "\n",
    "2). k+1-е дерево будет настраиваться на $y_i e^{-a(x_i)y_i} $, где $a_k$ - это предсказание первых k деревьев\n",
    "\n",
    "3). k+1-е дерево будет настраиваться на $\\frac{y_i exp(-a(x_i)y_i)}{1 + exp(-a(x_i)y_i)} $, где $a_k$ - это предсказание первых k деревьев"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Реализуем градиентный бустинг (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте класс градиентного бустинга для классификации. Ваша реализация бустинга должна работать по точности не более чем на 5 процентов хуже чем GradientBoostingClassifier из sklearn. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Детали реализации:\n",
    "\n",
    "-- должно поддерживаться 3 функции потерь\n",
    "\n",
    "-- сами базовые алгоритмы(деревья, линейные модели и тп) реализовать не надо, просто возьмите готовые из sklearn\n",
    "\n",
    "-- в качестве функции потерь для построения одного дерева используйте MSE\n",
    "\n",
    "-- шаг в бустинге можно не подбирать, можно брать константный\n",
    "\n",
    "-- можно брать разные модели в качестве инициализации бустинга\n",
    "\n",
    "-- должны поддерживаться следующие параметры:\n",
    "\n",
    "а) число итераций\n",
    "б) размер шага\n",
    "в) процент случайных фичей при построении одного дерева\n",
    "д) процент случайных объектов при построении одного дерева\n",
    "е) параметры базового алгоритма (передавайте через **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    sigm_value_x = 1.0 / (1 + np.exp(-x))\n",
    "    return sigm_value_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class MyGradientBoostingClassifier:\n",
    "\n",
    "    def __init__(self, loss='MSE', learning_rate=1, n_estimators=30, colsample=100, subsample=100, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        loss -- один из 3 лоссов:\n",
    "        learning_rate -- шаг бустинга\n",
    "        n_estimators -- число итераций\n",
    "        colsample -- процент рандомных признаков при обучнеии одного алгоритма\n",
    "        colsample -- процент рандомных объектов при обучнеии одного алгоритма\n",
    "        args, kwargs -- параметры  базовых моделей\n",
    "        \"\"\"\n",
    "        # Ваш код здесь\n",
    "        self.n_estimators = n_estimators\n",
    "        self.loss = loss\n",
    "        self.learning_rate = learning_rate\n",
    "        self.colsample = colsample\n",
    "        self.subsample = subsample\n",
    "        self.kw = kwargs\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y, base_model=DecisionTreeRegressor, init_model=None):\n",
    "        \"\"\"\n",
    "        X -- объекты для обучения:\n",
    "        y -- таргеты для обучения\n",
    "        base_model -- класс базовых моделей, например sklearn.tree.DecisionTreeRegressor\n",
    "        init_model -- класс для первой модели, если None то берем константу (только для посл задания)\n",
    "        \"\"\"\n",
    "        self.trees = []\n",
    "        self.init_model = init_model()\n",
    "        if not init_model:              \n",
    "            self.F0 = y.mean()\n",
    "        else:\n",
    "            self.init_model.fit(X, y)\n",
    "            self.F0 = self.init_model.predict(X)\n",
    "        Fm = self.F0 \n",
    "        for _ in range(self.n_estimators):\n",
    "            '''X_and_y = np.column_stack((X, y))\n",
    "            np.random.shuffle(X_and_y)\n",
    "            X_temp = X_and_y[:X.shape[0] * self.subsample // 100,:-1]\n",
    "            y_temp = X_and_y[:X.shape[0] * self.subsample // 100,-1:].T[0]\n",
    "            # print(X_temp)\n",
    "            print(y_temp)\n",
    "            X_temp = X_temp.T\n",
    "            np.random.shuffle(X_temp)\n",
    "            X_temp = X_temp.T\n",
    "            X_temp = X_temp[:, :X_temp.shape[1] * self.colsample // 100]'''\n",
    "            tree = base_model(**self.kw)\n",
    "            if self.loss == 'MSE':\n",
    "                diff = y - Fm\n",
    "            elif self.loss == 'Exponential':\n",
    "                diff = y * np.exp(-Fm * y)\n",
    "            elif self.loss == 'Logistic':\n",
    "                diff = y / (np.exp(Fm * y) + 1)\n",
    "            tree.fit(X, diff)\n",
    "            # print(tree.predict(X))\n",
    "            Fm += self.learning_rate * tree.predict(X)\n",
    "            self.trees.append(tree)\n",
    "        return self\n",
    "        \n",
    "    def predict(self, X):\n",
    "        '''y_hat = self.F0\n",
    "        for tree in self.trees:\n",
    "            np.random.shuffle(X)\n",
    "            X_temp = X[:X.shape[0] * self.subsample // 100,:]\n",
    "            # print(X_temp)\n",
    "            X_temp = X_temp.T\n",
    "            np.random.shuffle(X_temp)\n",
    "            X_temp = X_temp.T\n",
    "            X_temp = X_temp[:, :X_temp.shape[1] * self.colsample // 100]\n",
    "            y_hat += self.learning_rate * tree.predict(X_temp)'''\n",
    "        if self.init_model:\n",
    "            self.F0 = self.init_model.predict(X)\n",
    "        y_hat = self.F0 + self.learning_rate * np.sum([tree.predict(X) for tree in self.trees], axis=0)\n",
    "        if self.loss != 'MSE':\n",
    "            med = 0\n",
    "            # y_hat = sigmoid(y_hat)\n",
    "            # print(y_hat)\n",
    "            y_hat[np.where(y_hat > med)] = 1\n",
    "            y_hat[np.where(y_hat <= med)] = -1\n",
    "        return  y_hat      \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clf = MyGradientBoostingClassifier()\n",
    "clf = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "wine = load_wine()\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.1, stratify=wine.target, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 2., 2., 1., 1., 2., 1., 0., 2., 1., 0., 1., 0., 1., 1., 0., 0.,\n",
       "       2.])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_clf.fit(X_train, y_train)\n",
    "y_pred = my_clf.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 1, 1, 2, 1, 0, 2, 1, 0, 1, 0, 1, 1, 0, 0, 2])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "y_pred_l = clf.predict(X_test)\n",
    "y_pred_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9444444444444444\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "my_clf.fit(X_train, y_train)\n",
    "clf.fit(X_train, y_train)\n",
    "print(accuracy_score(y_pred=clf.predict(X_test), y_true=y_test))\n",
    "print(accuracy_score(y_pred=my_clf.predict(X_test), y_true=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 1, 1, 2, 1, 0, 2, 1, 0, 1, 0, 1, 1, 0, 0, 2])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=clf.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 2. 2. 1. 1. 2. 0. 0. 2. 1. 0. 1. 0. 1. 1. 0. 0. 2.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 2., 2., 1., 1., 2., 0., 0., 2., 1., 0., 1., 0., 1., 1., 0., 0.,\n",
       "       2.])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_clf.fit(X_train, y_train)\n",
    "y_pred=my_clf.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подбираем параметры (2 балла)\n",
    "\n",
    "Давайте попробуем применить Ваш бустинг для предсказаний цены домов в Калифорнии. Чтобы можно было попробовтаь разные функции потерь, переведем по порогу таргет в 2 класса: дорогие и дешевые дома."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В задании нужно\n",
    "\n",
    "1) Построить график точности в зависимости от числа итераций на валидации.\n",
    "\n",
    "2) Подобрать оптимальные параметры Вашего бустинга на валидации. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GroupKFold, cross_val_score, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "X, y = fetch_california_housing(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20640, 8) (20640,)\n"
     ]
    }
   ],
   "source": [
    "# Превращаем регрессию в классификацию\n",
    "y = (y > 2.0).astype(int)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 2 * (y - 1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1., ..., -1., -1., -1.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_clf = MyGradientBoostingClassifier(loss='Exponential')\n",
    "my_clf.fit(X, y).predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "n_estimators_list = np.arange(200, 619, 20) \n",
    "# alpha_list = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "scores = []\n",
    "\n",
    "for n_est in tqdm(n_estimators_list):\n",
    "    clf = MyGradientBoostingClassifier(\n",
    "        loss='Exponential',\n",
    "        n_estimators = n_est,\n",
    "        max_depth=3,\n",
    "        learning_rate=0.01\n",
    "    )\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.33, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    score = f1_score(clf.predict(X_test), y_test)\n",
    "    scores.append(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.plot(n_estimators_list, scores, label='score')\n",
    "plt.xlabel('n_estimators')\n",
    "plt.ylabel('f1')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8278599783471671"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MyGradientBoostingClassifier(\n",
    "        loss='Exponential',\n",
    "        n_estimators = 600,\n",
    "        max_depth = 3,\n",
    "        learning_rate = 0.01,\n",
    "        colsample = 1,\n",
    "        subsample = 1\n",
    "    )\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "score = f1_score(clf.predict(X_test), y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BooBag BagBoo (1 балл)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем объединить бустинг и бэгинг. Давайте\n",
    "\n",
    "1) в качестве базовой модели брать не дерево решений, а случайный лес (из sklearn)\n",
    "\n",
    "2) обучать N бустингов на бустрапированной выборке, а затем предикт усреднять"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуйте обе этих стратегии на данных из прошлого задания. Получилось ли улучшить качество? Почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8607506138197124"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_clf = MyGradientBoostingClassifier(loss='Exponential')\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42)\n",
    "my_clf.fit(X_train, y_train, base_model=RandomForestRegressor)\n",
    "score = f1_score(my_clf.predict(X_test), y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "clfs = []\n",
    "for _ in range(N):\n",
    "    my_clf = MyGradientBoostingClassifier(loss='Exponential')\n",
    "    \n",
    "    my_clf.fit(X_train, y_train)\n",
    "    clfs.append(my_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-864.0\n",
      "[-1. -1.  1. ... -1. -1.  1.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8073050008533881"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = 0\n",
    "for clf in clfs:\n",
    "    y_pred += clf.predict(X_test)\n",
    "y_pred = 1 / N * y_pred\n",
    "y_pred[np.where(y_pred > 0)] = 1\n",
    "y_pred[np.where(y_pred <= 0)] = -1\n",
    "print(sum(y_pred))\n",
    "print(y_test)\n",
    "score = f1_score(y_pred, y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Качество не улучшилось, хотя должно бы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Умная инициализация (1 балл)\n",
    "\n",
    "Попробуйте брать в качестве инициализации бустинга не константу, а какой-то алгоритм и уже от его предикта стартовать итерации бустинга. Попробуйте разные модели из sklearn: линейные модели, рандом форест, svm..\n",
    "\n",
    "Получилось ли улучшить качество? Почему?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/denis_system/miniconda3/envs/sphere-py37/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.861344537815126"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_clf = MyGradientBoostingClassifier(loss='Exponential')\n",
    "my_clf.fit(X_train, y_train, init_model=LogisticRegression, base_model=RandomForestRegressor)\n",
    "score = f1_score(my_clf.predict(X_test), y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "Качество немного выросло. Возможно, это связано с тем, что начальное приближение лучше, \n",
    "и внутренние модели успевают лучше обучиться."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Фидбек (бесценно)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Какие аспекты обучения  ансамблей Вам показались непонятными? Какое место стоит дополнительно объяснить?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ваш ответ здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Здесь Вы можете оставить отзыв о этой домашней работе или о всем курсе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ВАШ ОТЗЫВ ЗДЕСЬ\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
